#!/bin/bash
# ========================================================================
# COMMANDES UTILES - YOLOv11 Segmentation Project
# ========================================================================

# ========================================================================
# üöÄ D√âMARRAGE RAPIDE
# ========================================================================

# 1. Setup initial (une seule fois)
python setup.py

# 2. Entra√Ænement automatique (recommand√©)
python pipeline.py --config BALANCED

# 3. Voir les r√©sultats
tensorboard --logdir runs/


# ========================================================================
# üìö ENTRA√éNEMENT
# ========================================================================

# Entra√Ænement basique
python train.py

# Entra√Ænement rapide (prototype)
python pipeline.py --config FAST

# Entra√Ænement de haute qualit√©
python pipeline.py --config HIGH_QUALITY

# Entra√Ænement pour production
python pipeline.py --config PRODUCTION

# Entra√Ænement avec param√®tres personnalis√©s
# Modifier config.py et lancer train.py


# ========================================================================
# üìä √âVALUATION
# ========================================================================

# √âvaluer tous les mod√®les
python evaluate.py

# √âvaluer un mod√®le sp√©cifique
python evaluate.py models/yolov11m-seg_best_20250122_120000.pt

# Voir les r√©sultats d'√©valuation
# Fichiers JSON dans: evaluations/


# ========================================================================
# üîç CALCUL DU TAUX DE VIDES (VOID RATE)
# ========================================================================

# Calculer sur le test set
python void_rate_calculator.py

# Voir les r√©sultats
# Fichiers JSON dans: void_rate_results/


# ========================================================================
# üéØ INF√âRENCE
# ========================================================================

# Inf√©rence sur le test set complet
python inference.py

# Inf√©rence sur une image unique
python inference.py -i "path/to/image.jpg"

# Inf√©rence sur un dossier
python inference.py -d "path/to/images/"

# Inf√©rence avec seuil de confiance personnalis√©
python inference.py -c 0.6 -d "path/to/images/"

# Sauvegarder les images annot√©es
python inference.py -d "path/to/images/" -a

# Utiliser un mod√®le sp√©cifique
python inference.py -m "models/custom_model.pt" -d "path/to/images/"

# Sauvegarder les r√©sultats JSON
python inference.py -d "path/to/images/" -o "results.json"

# Combinaison compl√®te
python inference.py \
  -m "models/best_model.pt" \
  -d "path/to/images/" \
  -c 0.5 \
  -a \
  -o "inference_results.json"


# ========================================================================
# üîÑ PIPELINE AUTOMATIQUE
# ========================================================================

# Automatisation compl√®te (recommand√© pour production)
python pipeline.py

# Pipeline avec configuration sp√©cifique
python pipeline.py --config HIGH_QUALITY

# Pipeline en sautant l'entra√Ænement (utilise mod√®le existant)
python pipeline.py --skip-training

# Pipeline avec un mod√®le personnalis√©
python pipeline.py --skip-training --model "models/my_model.pt"

# Pipeline complet sans inf√©rence
python pipeline.py --skip-inference

# Pipeline pour les m√©tadonn√©es uniquement
python pipeline.py --skip-training --skip-inference


# ========================================================================
# üìä TENSORBOARD & MONITORING
# ========================================================================

# Lancer TensorBoard
tensorboard --logdir runs/

# Port personnalis√©
tensorboard --logdir runs/ --port 6007

# Lancer en arri√®re-plan
tensorboard --logdir runs/ --daemon

# Arr√™ter TensorBoard
# Linux/macOS:
pkill -f tensorboard
# Windows (PowerShell):
Get-Process tensorboard | Stop-Process


# ========================================================================
# üìù CONFIGURATION & PR√âSETS
# ========================================================================

# Voir toutes les configurations disponibles
python config.py

# Les presets disponibles sont:
# - QUICK_START
# - BALANCED_TRAINING (d√©faut)
# - HIGH_QUALITY_TRAINING
# - PRODUCTION_TRAINING
# - LIMITED_DATA_PRESET
# - MEMORY_EFFICIENT_PRESET


# ========================================================================
# üìÇ GESTION DES FICHIERS
# ========================================================================

# Lister les mod√®les disponibles
ls models/

# Lister les r√©sultats d'entra√Ænement
ls runs/

# Lister les √©valuations
ls evaluations/

# Lister les r√©sultats d'inf√©rence
ls inferences/

# Nettoyer les r√©sultats temporaires
rm -rf runs/*.zip  # Sur Linux/macOS
Remove-Item runs/*.zip  # Sur Windows PowerShell


# ========================================================================
# üîß D√âPANNAGE
# ========================================================================

# V√©rifier la version Python
python --version

# V√©rifier l'installation CUDA
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"

# V√©rifier YOLOv11
python -c "from ultralytics import YOLO; print(YOLO.__version__)"

# V√©rifier les packages
pip list | grep -E "torch|ultralytics|opencv"

# R√©installer les d√©pendances
pip install -r requirements.txt --upgrade

# R√©installer CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118


# ========================================================================
# üßπ NETTOYAGE
# ========================================================================

# Supprimer les mod√®les (sauf le meilleur)
rm models/*.pt  # √Ä utiliser avec prudence!

# Nettoyer les logs
rm -rf logs/

# Nettoyer compl√®tement
rm -rf runs/ evaluations/ inferences/ void_rate_results/


# ========================================================================
# üìä INSPECTION DES DONN√âES
# ========================================================================

# Compter les images d'entra√Ænement
find train/images -type f | wc -l

# Compter les images de validation
find valid/images -type f | wc -l

# Compter les images de test
find test/images -type f | wc -l

# V√©rifier la structure du YAML
python -c "import yaml; print(yaml.safe_load(open('data.yaml')))"


# ========================================================================
# üìì NOTEBOOK JUPYTER
# ========================================================================

# Lancer Jupyter Notebook
jupyter notebook

# Lancer Jupyter Lab
jupyter lab

# Ouvrir directement le notebook
jupyter notebook Training_Pipeline.ipynb


# ========================================================================
# üê≥ DOCKER (si besoin)
# ========================================================================

# Construire une image Docker (√† adapter)
# docker build -t yolov11-segmentation .

# Lancer le conteneur
# docker run -it --gpus all yolov11-segmentation

# Utiliser avec volumes
# docker run -it --gpus all -v $(pwd):/workspace yolov11-segmentation


# ========================================================================
# ‚ö° CONSEILS PERFORMANCE
# ========================================================================

# Augmenter batch size pour plus vite (plus de m√©moire GPU)
# CONFIG["batch_size"] = 32

# Diminuer batch size pour moins de m√©moire GPU
# CONFIG["batch_size"] = 4

# Utiliser demi-pr√©cision (FP16) si GPU supporte
# CONFIG["half"] = True

# Utiliser taille d'image plus petite pour inf√©rence plus rapide
# python inference.py -d "path/" -c 0.5 -i 416


# ========================================================================
# üìà R√âSULTATS & EXPORTS
# ========================================================================

# Exporter les r√©sultats en CSV
# Les fichiers results.csv sont dans runs/*/

# Exporter les m√©triques JSON
# Les fichiers sont dans evaluations/ et inferences/

# Analyser les r√©sultats (Python)
# import json
# with open('evaluations/evaluation_*.json') as f:
#     results = json.load(f)
#     print(results)


# ========================================================================
# üìù NOTES
# ========================================================================

# ‚Ä¢ Toujours commencer par: python setup.py
# ‚Ä¢ Pipeline.py automatise tout: python pipeline.py
# ‚Ä¢ TensorBoard pour monitoring: tensorboard --logdir runs/
# ‚Ä¢ Consulter README.md pour documentation compl√®te
# ‚Ä¢ Consulter QUICKSTART.py pour guide rapide
# ‚Ä¢ Les r√©sultats sont dans: models/, evaluations/, inferences/

# ========================================================================
