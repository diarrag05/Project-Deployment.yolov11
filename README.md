# ğŸ¯ Projet YOLOv11 - Segmentation et Calcul du Taux de Vides

SystÃ¨me complet de dÃ©tection et segmentation des dÃ©fauts (puces et trous) avec calcul automatique du taux de vides.

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#-vue-densemble)
2. [Installation](#-installation)
3. [EntraÃ®nement](#-entraÃ®nement)
4. [Ã‰valuation](#-Ã©valuation)
5. [Calcul du taux de vides](#-calcul-du-taux-de-vides)
6. [InfÃ©rence](#-infÃ©rence)
7. [Architecture](#-architecture)
8. [RÃ©sultats](#-rÃ©sultats)

## ğŸ” Vue d'ensemble

Ce projet utilise **YOLOv11-segmentation** pour:
- âœ… DÃ©tecter les composants (chips)
- âœ… DÃ©tecter les dÃ©fauts (trous)
- âœ… Segmenter les rÃ©gions avec masques prÃ©cis
- âœ… Calculer automatiquement le **taux de vides** (void_rate)

### Formule du taux de vides
```
void_rate = (somme des aires de trous / aire du composant) * 100 [%]
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- CUDA 11.8+ (optionnel, pour GPU)

### Ã‰tapes

1. **Cloner/AccÃ©der au projet**
```bash
cd "c:\Users\mdiia\OneDrive\Bureau\AIVANCITY\Cours\PGE4\Deployment n Maintenance\Project-Deployment.yolov11"
```

2. **CrÃ©er un environnement virtuel (recommandÃ©)**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate
```

3. **Installer les dÃ©pendances**
```bash
python setup.py
# ou
pip install -r requirements.txt
```

4. **VÃ©rifier l'installation**
```bash
python -c "import ultralytics; print(ultralytics.__version__)"
```

## ğŸ“ EntraÃ®nement

### Script principal: `train.py`

**DÃ©marrer l'entraÃ®nement**
```bash
python train.py
```

### Configuration avancÃ©e

Modifier les hyperparamÃ¨tres dans `train.py`:

```python
CONFIG = {
    "model_size": "m",           # Taille: n, s, m, l, x
    "epochs": 100,               # Nombre d'epochs
    "batch_size": 16,            # Taille du batch
    "img_size": 640,             # Taille des images
    "patience": 20,              # Early stopping
    "learning_rate": 0.001,      # Taux d'apprentissage
    "lr_scheduler": "cosine",    # Scheduler: linear, cosine, poly
    "weight_decay": 0.0005,      # RÃ©gularisation L2
}
```

### ParamÃ¨tres d'augmentation disponibles

```python
train_yolov11_segmentation(
    # Mosaic & Mixup
    mosaic=1.0,          # Augmentation Mosaic (0-1)
    
    # HSV
    hsv_h=0.015,         # HSV Hue
    hsv_s=0.7,           # HSV Saturation
    hsv_v=0.4,           # HSV Value
    
    # Transformations gÃ©omÃ©triques
    degrees=10.0,        # Rotation (degrÃ©s)
    translate=0.1,       # Translation
    scale=0.5,           # Scale
    flipud=0.5,          # Flip vertical
    fliplr=0.5,          # Flip horizontal
    perspective=0.0,     # Perspective
)
```

### Monitoring avec TensorBoard

```bash
tensorboard --logdir runs/
```

Puis accÃ©dez Ã : http://localhost:6006

### RÃ©sultats de l'entraÃ®nement

Les rÃ©sultats sont sauvegardÃ©s dans:
```
runs/
â”œâ”€â”€ yolov11m-seg_20250122_120000/
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â”œâ”€â”€ best.pt          # Meilleur modÃ¨le
â”‚   â”‚   â””â”€â”€ last.pt          # Dernier checkpoint
â”‚   â”œâ”€â”€ events.out.tfevents  # Logs TensorBoard
â”‚   â””â”€â”€ results.csv          # MÃ©triques
```

Le meilleur modÃ¨le est copiÃ© dans: `models/`

## ğŸ“Š Ã‰valuation

### Script: `evaluate.py`

**Ã‰valuer tous les modÃ¨les**
```bash
python evaluate.py
```

**Ã‰valuer un modÃ¨le spÃ©cifique**
```bash
python evaluate.py models/yolov11m-seg_best_20250122_120000.pt
```

### MÃ©triques calculÃ©es

#### Pour la **DÃ©tection** (Box):
- **mAP50**: PrÃ©cision moyenne Ã  IoU=50%
- **mAP50-95**: PrÃ©cision moyenne Ã  IoU=50% Ã  95%
- **PrÃ©cision**: TP / (TP + FP)
- **Rappel**: TP / (TP + FN)

#### Pour la **Segmentation** (Mask):
- **mAP50 (Mask)**: PrÃ©cision pour les masques
- **mAP50-95 (Mask)**: PrÃ©cision globale des masques
- **IoU par classe**: Intersection over Union pour chip et hole

### RÃ©sultats

Les rÃ©sultats JSON sont sauvegardÃ©s dans: `evaluations/`

## ğŸ” Calcul du Taux de Vides

### Script: `void_rate_calculator.py`

**Calculer le void_rate sur le test set**
```bash
python void_rate_calculator.py
```

### Usage avancÃ©

```python
from void_rate_calculator import VoidRateCalculator

# Initialiser
calculator = VoidRateCalculator("models/best_model.pt")

# Sur une image unique
result = calculator.calculate_void_rate("path/to/image.jpg")
print(f"Void Rate: {result['void_rate']:.2f}%")

# Sur un rÃ©pertoire
results = calculator.process_directory("path/to/images/")

# Sauvegarder les rÃ©sultats
calculator.save_results(results)
```

### RÃ©sultat d'une image

```json
{
    "image": "path/to/image.jpg",
    "void_rate": 15.35,
    "void_rate_percent": "15.35%",
    "hole_area_pixels": 15000,
    "chip_area_pixels": 97600,
    "num_holes": 3,
    "num_chips": 1,
    "image_resolution": "640x640"
}
```

### Statistiques globales

```json
{
    "num_images": 50,
    "avg_void_rate": 18.45,
    "min_void_rate": 2.10,
    "max_void_rate": 35.80,
    "std_void_rate": 8.23
}
```

## ğŸ¯ InfÃ©rence

### Script: `inference.py`

**InfÃ©rence sur le test set**
```bash
python inference.py
```

**InfÃ©rence sur une image unique**
```bash
python inference.py -i "path/to/image.jpg"
```

**InfÃ©rence sur un rÃ©pertoire**
```bash
python inference.py -d "path/to/images/"
```

**Avec modÃ¨le personnalisÃ©**
```bash
python inference.py -m "models/custom_model.pt" -d "path/to/images/"
```

**Avec seuil de confiance personnalisÃ©**
```bash
python inference.py -c 0.6 -d "path/to/images/"
```

**Sauvegarder les images annotÃ©es**
```bash
python inference.py -d "path/to/images/" -a
```

**Sauvegarder les rÃ©sultats**
```bash
python inference.py -d "path/to/images/" -o "results.json"
```

### RÃ©sultat d'infÃ©rence

```json
{
    "image_path": "test/images/image_001.jpg",
    "image_name": "image_001.jpg",
    "resolution": "640x640",
    "model_used": "yolov11m-seg_best.pt",
    "confidence_threshold": 0.5,
    "num_detections": 4,
    "chip_area_pixels": 98000,
    "hole_area_pixels": 16500,
    "void_rate": 16.84,
    "void_rate_percent": "16.84%",
    "detections": [
        {
            "id": 0,
            "class": "chip",
            "confidence": 0.96,
            "area_pixels": 98000,
            "bbox": {"x1": 10, "y1": 20, "x2": 630, "y2": 640}
        },
        {
            "id": 1,
            "class": "hole",
            "confidence": 0.89,
            "area_pixels": 4500,
            "bbox": {"x1": 100, "y1": 150, "x2": 200, "y2": 250}
        }
    ]
}
```

## ğŸ“ Architecture

```
Project-Deployment.yolov11/
â”œâ”€â”€ data.yaml                      # Configuration du dataset
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ setup.py                       # Script de configuration
â”‚
â”œâ”€â”€ train.py                       # ğŸ“ EntraÃ®nement
â”œâ”€â”€ evaluate.py                    # ğŸ“Š Ã‰valuation
â”œâ”€â”€ void_rate_calculator.py        # ğŸ” Calcul du taux de vides
â”œâ”€â”€ inference.py                   # ğŸ¯ InfÃ©rence
â”‚
â”œâ”€â”€ train/                         # Dataset d'entraÃ®nement
â”‚   â”œâ”€â”€ images/                    # Images
â”‚   â””â”€â”€ labels/                    # Annotations YOLO
â”‚
â”œâ”€â”€ valid/                         # Dataset de validation
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”‚
â”œâ”€â”€ test/                          # Dataset de test
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”‚
â”œâ”€â”€ models/                        # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ yolov11m-seg_best_*.pt
â”‚
â”œâ”€â”€ runs/                          # RÃ©sultats d'entraÃ®nement
â”‚   â””â”€â”€ yolov11m-seg_*/
â”‚       â”œâ”€â”€ weights/
â”‚       â”œâ”€â”€ events.out.tfevents
â”‚       â””â”€â”€ results.csv
â”‚
â”œâ”€â”€ evaluations/                   # RÃ©sultats d'Ã©valuation
â”‚   â””â”€â”€ evaluation_*.json
â”‚
â”œâ”€â”€ void_rate_results/             # RÃ©sultats void_rate
â”‚   â””â”€â”€ void_rate_*.json
â”‚
â””â”€â”€ inferences/                    # RÃ©sultats d'infÃ©rence
    â”œâ”€â”€ inference_*.json
    â””â”€â”€ annotated_*.jpg
```

## ğŸ“ˆ RÃ©sultats Attendus

### Performance de dÃ©tection
- **mAP50 (Box)**: 0.85+
- **mAP50-95 (Box)**: 0.75+
- **PrÃ©cision**: 0.90+
- **Rappel**: 0.85+

### Performance de segmentation
- **mAP50 (Mask)**: 0.82+
- **mAP50-95 (Mask)**: 0.70+

### Vitesse d'infÃ©rence
- **CPU**: ~500-1000ms/image
- **GPU (RTX 3060)**: ~50-100ms/image

## ğŸ”§ Tuning des HyperparamÃ¨tres

### Pour amÃ©liorer la prÃ©cision
```python
CONFIG = {
    "epochs": 150,           # Plus d'epochs
    "batch_size": 8,         # Batch plus petit = gradient plus prÃ©cis
    "learning_rate": 0.0005, # LR plus faible
    "weight_decay": 0.001,   # RÃ©gularisation plus forte
}
```

### Pour la vitesse (infÃ©rence)
```python
CONFIG = {
    "model_size": "n",       # Plus petit modÃ¨le
    "img_size": 416,         # Images plus petites
}
```

### Pour l'Ã©quilibre (recommandÃ©)
```python
CONFIG = {
    "model_size": "m",
    "epochs": 100,
    "batch_size": 16,
    "img_size": 640,
    "learning_rate": 0.001,
    "lr_scheduler": "cosine",
}
```

## ğŸ› Troubleshooting

### âŒ CUDA out of memory
```python
# RÃ©duire batch_size
CONFIG["batch_size"] = 8

# ou rÃ©duire img_size
CONFIG["img_size"] = 416
```

### âŒ ModÃ¨le ne converge pas
```python
# RÃ©duire learning_rate
CONFIG["learning_rate"] = 0.0005

# Augmenter epochs
CONFIG["epochs"] = 200
```

### âŒ Pas de GPU dÃ©tectÃ©
```bash
# VÃ©rifier CUDA
python -c "import torch; print(torch.cuda.is_available())"

# RÃ©installer torch pour CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“š Ressources

- [YOLOv11 Docs](https://docs.ultralytics.com/models/yolov11/)
- [Ultralytics GitHub](https://github.com/ultralytics/ultralytics)
- [TensorBoard Guide](https://www.tensorflow.org/tensorboard/get_started)

## ğŸ“ Licence

Ce projet utilise des donnÃ©es de Roboflow.

---

**CrÃ©Ã© pour**: Cours PGE4 - Deployment & Maintenance  
**Date**: Janvier 2025
